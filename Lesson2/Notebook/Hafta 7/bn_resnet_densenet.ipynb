{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating image dataset from csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Reading Csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/fashion-mnist_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_valid = pd.read_csv(\"data/fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      0       0       0       0       0       0       0       0       9   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "2      2       0       0       0       0       0       0      14      53   \n",
       "3      2       0       0       0       0       0       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       8  ...       103        87        56         0         0         0   \n",
       "1       0  ...        34         0         0         0         0         0   \n",
       "2      99  ...         0         0         0         0        63        53   \n",
       "3       0  ...       137       126       140         0       133       224   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2        31         0         0         0  \n",
       "3       222        56         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img = torch.tensor((df_train.loc[0][1:])).view(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img, cmap = \"gray\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat vs Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = torch.tensor((df_train.loc[0][1:])).view(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = torch.tensor((df_train.loc[1][1:])).view(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = torch.cat((img1, img2), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([56, 28])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(c1, cmap = \"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = torch.cat((img1, img2), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(c2, cmap = \"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.stack((img1, img2), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 28, 28])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(s[0], cmap = \"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(s[1], cmap = \"gray\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Reading images and corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_ds_from_csv(df):\n",
    "    imgs, labels = [], []\n",
    "    \n",
    "    for i in range(1, len(df)):\n",
    "        \n",
    "        \n",
    "        imgs.append(torch.tensor(df.loc[i][1:], dtype = torch.float32).view(28,28))\n",
    "        labels.append(torch.tensor(df.loc[i][0], dtype = torch.long))\n",
    "        \n",
    "    return torch.stack(imgs), torch.stack(labels).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_x, trn_y = create_ds_from_csv(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_x,val_y = create_ds_from_csv(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(72.9562), tensor(89.9665), tensor(-1.3771e-05), tensor(1.))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = trn_x.mean()\n",
    "std = trn_x.std()\n",
    "\n",
    "trn_x=(trn_x-mean)/std\n",
    "mean, std, trn_x.mean(), trn_x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0022), tensor(1.0034))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x = (val_x-mean)/std\n",
    "val_x.mean(), val_x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our model's setup from previous lectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): \n",
    "    return (x.exp()/(x.exp().sum(-1,keepdim=True)) + 1e-20).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(preds, actuals): \n",
    "    return -preds[range(actuals.shape[0]), actuals].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_acc(model):\n",
    "    return torch.stack([accuracy(model(xb), yb) for xb, yb in valid_dl]).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, yb): \n",
    "    return (torch.argmax(preds, dim=1, keepdim = True)==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(preds, targets):\n",
    "    preds = log_softmax(preds)\n",
    "    return nll(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs=5, valid_epoch=5):\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model = model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            \n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb.squeeze())\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "        \n",
    "        if epoch  % valid_epoch == 0:\n",
    "            model = model.eval()\n",
    "            print(validation_acc(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, x, y): \n",
    "        self.x,self.y = x,y\n",
    "    def __len__(self): \n",
    "        return len(self.x)\n",
    "    def __getitem__(self, i): \n",
    "        return self.x[i].view(-1,784).cuda(),self.y[i].cuda()\n",
    "\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, ds, bs): \n",
    "        self.ds, self.bs = ds, bs\n",
    "    def __iter__(self):\n",
    "        n = len(self.ds)\n",
    "        l = torch.randperm(n)\n",
    "\n",
    "        \n",
    "        for i in range(0, n, self.bs): \n",
    "            idxs_l = l[i:i+self.bs]\n",
    "            yield self.ds[idxs_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(trn_x, trn_y)\n",
    "valid_ds = Dataset(val_x,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, 256)\n",
    "valid_dl = DataLoader(valid_ds, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(784,60),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(60,10)\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5608919262886047\n",
      "0.7238802313804626\n",
      "0.7561067938804626\n",
      "0.77769535779953\n",
      "0.7944075465202332\n",
      "0.8071224093437195\n",
      "0.8069010972976685\n",
      "0.8119726181030273\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-181-62ecf8d4e5fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-168-1ce1f57ee26c>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, epochs, valid_epoch)\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\engin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \"\"\"\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\engin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model,50,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, x, y): \n",
    "        self.x,self.y = x,y\n",
    "    def __len__(self): \n",
    "        return len(self.x)\n",
    "    def __getitem__(self, i): \n",
    "        return self.x[i].view(-1,1,28,28).cuda(),self.y[i].cuda()\n",
    "\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, ds, bs): \n",
    "        self.ds, self.bs = ds, bs\n",
    "    def __iter__(self):\n",
    "        n = len(self.ds)\n",
    "        l = torch.randperm(n)\n",
    "\n",
    "        \n",
    "        for i in range(0, n, self.bs): \n",
    "            idxs_l = l[i:i+self.bs]\n",
    "            yield self.ds[idxs_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(trn_x, trn_y)\n",
    "valid_ds = Dataset(val_x,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, 256)\n",
    "valid_dl = DataLoader(valid_ds, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Func(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x): \n",
    "        return self.func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):      \n",
    "    return x.view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BatchNorm (BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: PyTorch's mom parameter is opposite of what we are generally talking\n",
    "# pytorch's momentum is like (1-momentum)\n",
    "# nn.Module.register_buffer()\n",
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, nf, momentum=0.1, eps=1e-5):\n",
    "        super().__init__()\n",
    "       \n",
    "        self.momentum,self.eps = momentum,eps\n",
    "        \n",
    "        self.alpha = nn.Parameter(torch.ones (nf,1,1))\n",
    "        self.beta  = nn.Parameter(torch.zeros(nf,1,1))\n",
    "        \n",
    "        self.register_buffer('variances',  torch.ones(1,nf,1,1))\n",
    "        self.register_buffer('means', torch.zeros(1,nf,1,1))\n",
    "\n",
    "    def update_mean_var(self, x):\n",
    "        \n",
    "        m = x.mean((0,2,3), keepdim=True)\n",
    "        v = x.var ((0,2,3), keepdim=True)\n",
    "        \n",
    "        self.means.lerp_(m, self.momentum)\n",
    "        self.variances.lerp_ (v, self.momentum)\n",
    "        return m,v\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            with torch.no_grad(): \n",
    "                m,v = self.update_mean_var(x)\n",
    "        \n",
    "        else: # Do not update in inference time, use calculated valued instead\n",
    "            m,v = self.means,self.variances\n",
    "        \n",
    "        x = (x-m) / (v+self.eps).sqrt()\n",
    "        \n",
    "        return x*self.alpha + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        nn.Conv2d(1, 8, 5, padding=2,stride=2), BatchNorm(8), nn.ReLU(),  #14\n",
    "        nn.Conv2d(8, 16, 3, padding=1,stride=2), BatchNorm(16), nn.ReLU(), # 7\n",
    "        nn.Conv2d(16, 32, 3, padding=1,stride=2), BatchNorm(32),nn.ReLU(), # 4\n",
    "        nn.Conv2d(32, 64, 3, padding=1,stride=2), nn.ReLU(), # 2\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        Func(flatten),\n",
    "        nn.Linear(64,10)\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight \t torch.Size([8, 1, 5, 5])\n",
      "0.bias \t torch.Size([8])\n",
      "1.alpha \t torch.Size([8, 1, 1])\n",
      "1.beta \t torch.Size([8, 1, 1])\n",
      "1.variances \t torch.Size([1, 8, 1, 1])\n",
      "1.means \t torch.Size([1, 8, 1, 1])\n",
      "3.weight \t torch.Size([16, 8, 3, 3])\n",
      "3.bias \t torch.Size([16])\n",
      "4.alpha \t torch.Size([16, 1, 1])\n",
      "4.beta \t torch.Size([16, 1, 1])\n",
      "4.variances \t torch.Size([1, 16, 1, 1])\n",
      "4.means \t torch.Size([1, 16, 1, 1])\n",
      "6.weight \t torch.Size([32, 16, 3, 3])\n",
      "6.bias \t torch.Size([32])\n",
      "7.alpha \t torch.Size([32, 1, 1])\n",
      "7.beta \t torch.Size([32, 1, 1])\n",
      "7.variances \t torch.Size([1, 32, 1, 1])\n",
      "7.means \t torch.Size([1, 32, 1, 1])\n",
      "9.weight \t torch.Size([64, 32, 3, 3])\n",
      "9.bias \t torch.Size([64])\n",
      "13.weight \t torch.Size([10, 64])\n",
      "13.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight\n",
      "0.bias\n",
      "1.alpha\n",
      "1.beta\n",
      "3.weight\n",
      "3.bias\n",
      "4.alpha\n",
      "4.beta\n",
      "6.weight\n",
      "6.bias\n",
      "7.alpha\n",
      "7.beta\n",
      "9.weight\n",
      "9.bias\n",
      "13.weight\n",
      "13.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8226367235183716\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-554-901ad52ad9f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-498-4d93441774e7>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, epochs, valid_epoch)\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\engin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \"\"\"\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\engin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model,80,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BN after ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        nn.Conv2d(1, 8, 5, padding=2,stride=2, bias = False), nn.ReLU(), nn.BatchNorm2d(8), #14\n",
    "        nn.Conv2d(8, 16, 3, padding=1,stride=2, bias = False), nn.ReLU(),nn.BatchNorm2d(16), # 7\n",
    "        nn.Conv2d(16, 32, 3, padding=1,stride=2, bias = False), nn.ReLU(),nn.BatchNorm2d(32), # 4\n",
    "        nn.Conv2d(32, 64, 3, padding=1,stride=2, bias = False), nn.ReLU(),nn.BatchNorm2d(64), # 2\n",
    "        #Func(print_t),\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        Func(flatten),\n",
    "        nn.Linear(64,10)\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8701042532920837\n",
      "0.8764192461967468\n",
      "0.8714714050292969\n",
      "0.8866015672683716\n",
      "0.8948112726211548\n"
     ]
    }
   ],
   "source": [
    "train(model,50,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BN before ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        nn.Conv2d(1, 8, 5, padding=2,stride=2, bias = False),nn.BatchNorm2d(8), nn.ReLU(),  #14\n",
    "        nn.Conv2d(8, 16, 3, padding=1,stride=2, bias = False),nn.BatchNorm2d(16), nn.ReLU(), # 7\n",
    "        nn.Conv2d(16, 32, 3, padding=1,stride=2, bias = False), nn.BatchNorm2d(32),nn.ReLU(), # 4\n",
    "        nn.Conv2d(32, 64, 3, padding=1,stride=2, bias = False), nn.BatchNorm2d(64), nn.ReLU(), # 2\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        Func(flatten),\n",
    "        nn.Linear(64,10)\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8226367235183716\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-554-901ad52ad9f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-498-4d93441774e7>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, epochs, valid_epoch)\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\engin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \"\"\"\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\engin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model,80,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With BN and our custom init function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain(a):\n",
    "    return math.sqrt(2.0 / (1 + a**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaiming for uniform init\n",
    "def kaiming_uniform(x, a):\n",
    "    n = x[0].shape.numel()\n",
    "    std = gain(a) / math.sqrt(n)\n",
    "    bound = math.sqrt(3.) * std\n",
    "    x.data.uniform_(-bound, bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        nn.Conv2d(1, 8, 5, padding=2,stride=2), nn.ReLU(), nn.BatchNorm2d(8), #14\n",
    "        nn.Conv2d(8, 16, 3, padding=1,stride=2), nn.ReLU(),nn.BatchNorm2d(16), # 7\n",
    "        nn.Conv2d(16, 32, 3, padding=1,stride=2), nn.ReLU(),nn.BatchNorm2d(32), # 4\n",
    "        nn.Conv2d(32, 64, 3, padding=1,stride=2), nn.ReLU(),nn.BatchNorm2d(64), # 2\n",
    "        #Func(print_t),\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        Func(flatten),\n",
    "        nn.Linear(64,10)\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in model:\n",
    "    if isinstance(l, nn.Conv2d):\n",
    "        kaiming_uniform(l.weight, a = 0)\n",
    "        l.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6521159410476685\n",
      "0.8276106715202332\n",
      "0.8633724451065063\n",
      "0.8784114718437195\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-424-901ad52ad9f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-168-1ce1f57ee26c>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, epochs, valid_epoch)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m             \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\engin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\engin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\engin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\engin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;31m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# use cumulative moving average\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                     \u001b[0mexponential_average_factor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model,80,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### x without ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, nf):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(nf, nf, 3, padding=1,stride=1)\n",
    "        self.conv2 = nn.Conv2d(nf, nf, 3, padding=1,stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.conv2(self.conv1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        nn.Conv2d(1, 8, 5, padding=2,stride=2), nn.ReLU(), nn.BatchNorm2d(8),\n",
    "        ResBlock(8),\n",
    "        nn.Conv2d(8, 16, 3, padding=1,stride=2), nn.ReLU(),nn.BatchNorm2d(16), \n",
    "        ResBlock(16),\n",
    "        nn.Conv2d(16, 32, 3, padding=1,stride=2), nn.ReLU(),nn.BatchNorm2d(32),\n",
    "        ResBlock(32),\n",
    "        nn.Conv2d(32, 32, 3, padding=1,stride=2), nn.ReLU(),\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        Func(flatten),\n",
    "        nn.Linear(32,10)\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5810156464576721\n",
      "0.8605338931083679\n",
      "0.8770443201065063\n",
      "0.891894519329071\n",
      "0.8917903900146484\n",
      "0.8946093916893005\n",
      "0.8959831595420837\n",
      "0.9000846743583679\n"
     ]
    }
   ],
   "source": [
    "train(model,80,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### x with ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, nf):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(nf, nf, 3, padding=1,stride=1)\n",
    "        self.conv2 = nn.Conv2d(nf, nf, 3, padding=1,stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + F.relu(self.conv2(self.conv1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        nn.Conv2d(1, 8, 5, padding=2,stride=2), nn.ReLU(), nn.BatchNorm2d(8),\n",
    "        ResBlock(8), nn.ReLU(), nn.BatchNorm2d(8),\n",
    "        nn.Conv2d(8, 16, 3, padding=1,stride=2), nn.ReLU(),nn.BatchNorm2d(16), \n",
    "        ResBlock(16), nn.ReLU(), nn.BatchNorm2d(16),\n",
    "        nn.Conv2d(16, 32, 3, padding=1,stride=2), nn.ReLU(),nn.BatchNorm2d(32),\n",
    "        ResBlock(32), nn.ReLU(), nn.BatchNorm2d(32),\n",
    "        nn.Conv2d(32, 32, 3, padding=1,stride=2), nn.ReLU(), \n",
    "        #Func(print_t),\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        Func(flatten),\n",
    "        nn.Linear(32,10)\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41594401001930237\n",
      "0.8426367044448853\n",
      "0.8749870657920837\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-451-901ad52ad9f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-168-1ce1f57ee26c>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, epochs, valid_epoch)\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalid_epoch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\engin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m                     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model,80,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, nf):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(nf, nf, 3, padding=1,stride=1)\n",
    "        self.conv2 = nn.Conv2d(nf, nf, 3, padding=1,stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.cat((x, self.conv2(self.conv1(x))), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        nn.Conv2d(1, 8, 5, padding=2,stride=2), nn.ReLU(), nn.BatchNorm2d(8),\n",
    "        DenseBlock(8),\n",
    "        nn.Conv2d(16, 32, 3, padding=1,stride=2), nn.ReLU(),nn.BatchNorm2d(32), \n",
    "        DenseBlock(32),\n",
    "        nn.Conv2d(64, 100, 3, padding=1,stride=2), nn.ReLU(),nn.BatchNorm2d(100),\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        Func(flatten),\n",
    "        nn.Linear(100,10)\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [256 x 100], m2: [2304 x 600] at C:/w/1/s/windows/pytorch/aten/src\\THC/generic/THCTensorMathBlas.cu:290",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-583-901ad52ad9f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-498-4d93441774e7>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, epochs, valid_epoch)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\engin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\engin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\engin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\engin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\engin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1368\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [256 x 100], m2: [2304 x 600] at C:/w/1/s/windows/pytorch/aten/src\\THC/generic/THCTensorMathBlas.cu:290"
     ]
    }
   ],
   "source": [
    "train(model,80,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
